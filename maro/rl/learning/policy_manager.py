# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

import time
from abc import ABC, abstractmethod
from collections import defaultdict
from multiprocessing import Pipe, Process
from os import getcwd
from typing import Callable, Dict, List

from maro.communication import Proxy, SessionMessage, SessionType
from maro.rl.policy import RLPolicy
from maro.rl.utils import MsgKey, MsgTag
from maro.utils import Logger


class AbsPolicyManager(ABC):
    """Facility that controls policy update and serves the latest policy states."""
    def __init__(self):
        super().__init__()

    @abstractmethod
    def update(self, rollout_info: Dict[str, list]):
        """Update policies using roll-out information.

        The roll-out information is grouped by policy name and may be either a training batch or a list of loss
        information dictionaries computed directly by roll-out workers.
        """
        raise NotImplementedError

    @abstractmethod
    def get_state(self):
        """Get the latest policy states."""
        raise NotImplementedError

    @abstractmethod
    def get_version(self):
        """Get the collective policy version."""
        raise NotImplementedError

    def server(self, group: str, num_actors: int, max_lag: int = 0, proxy_kwargs: dict = {}, log_dir: str = getcwd()):
        """Run a server process.

        The process serves the latest policy states to a set of remote actors and receives simulated experiences from
        them.

        Args:
            group (str): Group name for the cluster that includes the server and all actors.
            num_actors (int): Number of remote actors to collect simulation experiences.
            max_lag (int): Maximum policy version lag allowed for experiences collected from remote actors. Experiences
                collected using policy versions older than (current_version - max_lag) will be discarded. Defaults to 0,
                in which case only experiences collected using the latest policy version will be returned.
            proxy_kwargs: Keyword parameters for the internal ``Proxy`` instance. See ``Proxy`` class
                for details. Defaults to the empty dictionary.
            log_dir (str): Directory to store logs in. Defaults to the current working directory.
        """
        peers = {"actor": num_actors}
        name = "POLICY_SERVER"
        proxy = Proxy(group, "policy_server", peers, component_name=name, **proxy_kwargs)
        logger = Logger(name, dump_folder=log_dir)

        num_active_actors = num_actors
        for msg in proxy.receive():
            if msg.tag == MsgTag.GET_INITIAL_POLICY_STATE:
                proxy.reply(
                    msg, tag=MsgTag.POLICY_STATE,
                    body={MsgKey.POLICY_STATE: self.get_state(), MsgKey.VERSION: self.get_version()}
                )
            elif msg.tag == MsgTag.SAMPLE_DONE:
                if self.get_version() - msg.body[MsgKey.VERSION] > max_lag:
                    logger.info(
                        f"Ignored a message because it contains experiences generated using a stale policy version. "
                        f"Expected experiences generated using policy versions no earlier than "
                        f"{self.get_version() - max_lag}, got {msg.body[MsgKey.VERSION]}"
                    )
                else:
                    self.update(msg.body[MsgKey.ROLLOUT_INFO])
                proxy.reply(
                    msg, tag=MsgTag.POLICY_STATE,
                    body={MsgKey.POLICY_STATE: self.get_state(), MsgKey.VERSION: self.get_version()}
                )
            elif msg.tag == MsgTag.DONE:
                num_active_actors -= 1
                if num_active_actors == 0:
                    proxy.close()
                    return


class SimplePolicyManager(AbsPolicyManager):
    """Policy manager that contains all policy instances.

    Args:
        create_policy_func_dict (dict): Dictionary that maps policy names to policy creators. A policy creator is a
            function that takes policy name as the only parameter and return an ``RLPolicy`` instance.
        parallel (bool): If True, the policies will be created in separate processes so that they can be updated in
            parallel. Otherwise, they will be created by the manager itself, in which case they can only be updated
            sequentially. Defaults to False.
        log_dir (str): Directory to store logs in. A ``Logger`` with tag "POLICY_MANAGER" will be created at init
            time and this directory will be used to save the log files generated by it. Defaults to the current
            working directory.
    """
    def __init__(
        self,
        create_policy_func_dict: Dict[str, Callable[[str], RLPolicy]],
        parallel: bool = False,
        log_dir: str = getcwd()
    ):
        super().__init__()
        self._policy_names = list(create_policy_func_dict.keys())
        self._parallel = parallel
        self._logger = Logger("POLICY_MANAGER", dump_folder=log_dir)
        if parallel:
            self._logger.info("Spawning policy host processes")
            self._state_cache = {}
            self._policy_hosts = []
            self._manager_end = {}

            def _policy_host(name, create_policy_func, conn):
                policy = create_policy_func(name)
                conn.send({"type": "init", "policy_state": policy.get_state()})
                while True:
                    msg = conn.recv()
                    if msg["type"] == "learn":
                        info_list = msg["rollout_info"]
                        if not isinstance(info_list, list):
                            info_list = [info_list]
                        if "loss" in info_list[0]:
                            policy.update(info_list)
                        else:
                            policy.learn(info_list)

                        conn.send({"type": "learn_done", "policy_state": policy.get_state()})
                    elif msg["type"] == "quit":
                        break

            for name, create_policy_func in create_policy_func_dict.items():
                manager_end, host_end = Pipe()
                self._manager_end[name] = manager_end
                host = Process(target=_policy_host, args=(name, create_policy_func, host_end))
                self._policy_hosts.append(host)
                host.start()

            for policy_name, conn in self._manager_end.items():
                msg = conn.recv()
                if msg["type"] == "init":
                    self._state_cache[policy_name] = msg["policy_state"]
                    self._logger.info(f"Initial state for policy {policy_name} cached")
        else:
            self._logger.info("Creating policy instances locally")
            self._policy_dict = {name: func(name) for name, func in create_policy_func_dict.items()}

        self._version = 0

    def update(self, rollout_info: Dict[str, list]):
        """Update policies using roll-out information.

        The roll-out information is grouped by policy name and may be either a training batch or a list of loss
        information dictionaries computed directly by roll-out workers.
        """
        t0 = time.time()
        if self._parallel:
            for policy_name, info_list in rollout_info.items():
                self._manager_end[policy_name].send({"type": "learn", "rollout_info": info_list})
            for policy_name, conn in self._manager_end.items():
                msg = conn.recv()
                if msg["type"] == "learn_done":
                    self._state_cache[policy_name] = msg["policy_state"]
                    self._logger.info(f"Cached state for policy {policy_name}")
        else:
            for policy_name, info in rollout_info.items():
                if isinstance(info, list):
                    self._policy_dict[policy_name].update(info)
                else:
                    self._policy_dict[policy_name].learn(info)

        self._logger.info(f"Updated policies {list(rollout_info.keys())}")
        self._version += 1
        self._logger.info(f"policy update time: {time.time() - t0}")

    def get_state(self):
        """Get the latest policy states."""
        if self._parallel:
            return self._state_cache
        else:
            return {name: policy.get_state() for name, policy in self._policy_dict.items()}

    def get_version(self):
        """Get the collective policy version."""
        return self._version

    def exit(self):
        """Tell the policy host processes to exit."""
        if self._parallel:
            for conn in self._manager_end.values():
                conn.send({"type": "quit"})


class DistributedPolicyManager(AbsPolicyManager):
    """Policy manager that communicates with a set of remote nodes that house the policy instances.

    Args:
        policy_names (List[str]): Names of the registered policies.
        group (str): Group name for the cluster consisting of the manager and all policy hosts.
        num_hosts (int): Number of hosts. The hosts will be identified by "POLICY_HOST.i", where 0 <= i < num_hosts.
        log_dir (str): Directory to store logs in. A ``Logger`` with tag "POLICY_MANAGER" will be created at init
            time and this directory will be used to save the log files generated by it. Defaults to the current
            working directory.
        proxy_kwargs: Keyword parameters for the internal ``Proxy`` instance. See ``Proxy`` class
            for details. Defaults to the empty dictionary.
    """
    def __init__(
        self,
        policy_names: List[str],
        group: str,
        num_hosts: int,
        log_dir: str = getcwd(),
        proxy_kwargs: dict = {}
    ):
        super().__init__()
        self._policy_names = policy_names
        peers = {"policy_host": num_hosts}
        self._proxy = Proxy(group, "policy_manager", peers, component_name="POLICY_MANAGER", **proxy_kwargs)
        self._logger = Logger("POLICY_MANAGER", dump_folder=log_dir)

        self._policy2host = {}
        self._host2policies = defaultdict(list)

        # assign policies to hosts
        for i, name in enumerate(self._policy_names):
            host_id = i % num_hosts
            self._policy2host[name] = f"POLICY_HOST.{host_id}"
            self._host2policies[f"POLICY_HOST.{host_id}"].append(name)

        self._logger.info(f"Policy assignment: {self._policy2host}")

        # ask the hosts to initialize the assigned policies
        for host_name, policy_names in self._host2policies.items():
            self._proxy.isend(SessionMessage(
                MsgTag.INIT_POLICIES, self._proxy.name, host_name, body={MsgKey.POLICY_NAMES: policy_names}
            ))

        # cache the initial policy states
        self._state_cache, dones = {}, 0
        for msg in self._proxy.receive():
            if msg.tag == MsgTag.INIT_POLICIES_DONE:
                for policy_name, policy_state in msg.body[MsgKey.POLICY_STATE].items():
                    self._state_cache[policy_name] = policy_state
                    self._logger.info(f"Cached state for policy {policy_name}")
                dones += 1
                if dones == num_hosts:
                    break

        self._version = 0

    def update(self, rollout_info: Dict[str, list]):
        """Update policies using roll-out information.

        The roll-out information is grouped by policy name and may be either a training batch or a list if loss
        information dictionaries computed directly by roll-out workers.
        """
        msg_dict = defaultdict(lambda: defaultdict(dict))
        for policy_name, info in rollout_info.items():
            host_id_str = self._policy2host[policy_name]
            msg_dict[host_id_str][MsgKey.ROLLOUT_INFO][policy_name] = info

        dones = 0
        self._proxy.iscatter(MsgTag.LEARN, SessionType.TASK, list(msg_dict.items()))
        for msg in self._proxy.receive():
            if msg.tag == MsgTag.LEARN_DONE:
                for policy_name, policy_state in msg.body[MsgKey.POLICY_STATE].items():
                    self._state_cache[policy_name] = policy_state
                    self._logger.info(f"Cached state for policy {policy_name}")
                dones += 1
                if dones == len(msg_dict):
                    break

        self._version += 1
        self._logger.info(f"Updated policies {list(rollout_info.keys())}")

    def get_state(self):
        """Get the latest policy states."""
        return self._state_cache

    def get_version(self):
        """Get the collective policy version."""
        return self._version

    def exit(self):
        """Tell the remote policy hosts to exit."""
        self._proxy.ibroadcast("policy_host", MsgTag.EXIT, SessionType.NOTIFICATION)
        self._proxy.close()
        self._logger.info("Exiting...")


def policy_host(
    create_policy_func_dict: Dict[str, Callable[[str], RLPolicy]],
    host_idx: int,
    group: str,
    proxy_kwargs: dict = {},
    log_dir: str = getcwd()
):
    """Policy host process that can be launched on separate computation nodes.

    Args:
        create_policy_func_dict (dict): A dictionary mapping policy names to functions that create them. The policy
            creation function should have policy name as the only parameter and return an ``RLPolicy`` instance.
        host_idx (int): Integer host index. The host's ID in the cluster will be "POLICY_HOST.{host_idx}".
        group (str): Group name for the training cluster, which includes all policy hosts and a policy manager that
            manages them.
        proxy_kwargs: Keyword parameters for the internal ``Proxy`` instance. See ``Proxy`` class
            for details. Defaults to the empty dictionary.
        log_dir (str): Directory to store logs in. Defaults to the current working directory.
    """
    policy_dict = {}
    proxy = Proxy(group, "policy_host", {"policy_manager": 1}, component_name=f"POLICY_HOST.{host_idx}", **proxy_kwargs)
    logger = Logger(proxy.name, dump_folder=log_dir)

    for msg in proxy.receive():
        if msg.tag == MsgTag.EXIT:
            logger.info("Exiting...")
            proxy.close()
            break

        if msg.tag == MsgTag.INIT_POLICIES:
            for name in msg.body[MsgKey.POLICY_NAMES]:
                policy_dict[name] = create_policy_func_dict[name](name)

            logger.info(f"Initialized policies {msg.body[MsgKey.POLICY_NAMES]}")
            proxy.reply(
                msg,
                tag=MsgTag.INIT_POLICIES_DONE,
                body={MsgKey.POLICY_STATE: {name: policy.get_state() for name, policy in policy_dict.items()}}
            )
        elif msg.tag == MsgTag.LEARN:
            t0 = time.time()
            for name, info in msg.body[MsgKey.ROLLOUT_INFO].items():
                if isinstance(info, list):
                    logger.info("updating with loss info")
                    policy_dict[name].update(info)
                else:
                    logger.info("learning from batch")
                    policy_dict[name].learn(info)

            msg_body = {
                MsgKey.POLICY_STATE: {name: policy_dict[name].get_state() for name in msg.body[MsgKey.ROLLOUT_INFO]}
            }
            logger.debug(f"total policy update time: {time.time() - t0}")
            proxy.reply(msg, tag=MsgTag.LEARN_DONE, body=msg_body)
