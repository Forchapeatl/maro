# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

from typing import List

import numpy as np


class State:
    """Convenience class to be used in an environment wrapper's post-step processing function.

    Args:
        state: Output of the environment wrapper's ``get_state``.
        action: Output of the ``AgentWrapper`` that interacts with environment wrapper.
        env_action: Output of the environment wrapper's ``to_env_action``.
        reward: Output of the environmet wrapper's ``get_reward``.
        next_state: The state immediately following ``state``.
        info: Output of the environment wrapper's ``get_transition_info``.
    """

    __slots__ = ["input", "meta"]

    def __init__(self, input: np.ndarray, meta=None):
        self.input = input
        self.meta = meta

    def 


class Transition:
    """Convenience class to be used in an environment wrapper's post-step processing function.

    Args:
        state: ``State`` object generated by the environment wrapper's ``get_state``.
        action: Output of the ``AgentWrapper`` that interacts with environment wrapper.
        env_action: Output of the environment wrapper's ``to_env_action``.
        reward: Output of the environmet wrapper's ``get_reward``.
        next_state: The state immediately following ``state``.
        info: Output of the environment wrapper's ``get_transition_info``.
    """

    __slots__ = ["state", "action", "env_action", "reward", "next_state", "info"]

    def __init__(self, state: State, action, env_action, reward, next_state: State, info):
        self.state = state
        self.action = action
        self.env_action = env_action
        self.reward = reward
        self.next_state = next_state
        self.info = info


class Trajectory:
    """Sequence of transitions for an agent.

    Args:
        states: Sequence of ``State`` objects traversed during simulation.
        actions: Sequence of actions taken in response to the states.
        rewards: Sequence of rewards received as a result of the actions.
        info: Sequence of each transition's auxillary information.
    """

    __slots__ = ["states", "state_meta", "actions", "rewards", "info", "max_len", "terminal"]

    def __init__(
        self,
        states: np.ndarray,
        state_meta,
        actions: np.ndarray,
        rewards: np.ndarray,
        info: list,
        max_len: int = 10000,
        terminal: bool = True
    ):
        self.states = states
        self.state_meta = state_meta
        self.actions = actions
        self.rewards = rewards
        self.info = info
        self.max_len = max_len
        self.terminal = terminal
